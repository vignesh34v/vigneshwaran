{
  
    
        "post0": {
            "title": "Title",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline . import torch . from sklearn.metrics import mean_squared_error . %load_ext autoreload %autoreload 2 . df = pd.read_csv(&#39;processed-temperature.csv&#39;) . df.columns . Index([&#39;Unnamed: 0&#39;, &#39;Date&#39;, &#39;temperature&#39;], dtype=&#39;object&#39;) . rain = pd.read_csv(&#39;chennai_reservoir_rainfall.csv&#39;) . type(rain[&quot;Date&quot;]) . pandas.core.series.Series . type(df[&quot;Date&quot;]) . pandas.core.series.Series . rain.head() . Date POONDI CHOLAVARAM REDHILLS CHEMBARAMBAKKAM . 0 01-01-2004 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 02-01-2004 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 03-01-2004 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 04-01-2004 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 05-01-2004 | 0.0 | 0.0 | 0.0 | 0.0 | . rain[&quot;Date&quot;] = pd.to_datetime(rain[&quot;Date&quot;], format=&#39;%d-%m-%Y&#39;) . rain[&quot;Date&quot;] = pd.to_datetime(rain[&quot;Date&quot;], format=&#39;%m-%d-%Y&#39;) . rain.head() . Date POONDI CHOLAVARAM REDHILLS CHEMBARAMBAKKAM . 0 2004-01-01 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 2004-01-02 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 2004-01-03 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 2004-01-04 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 2004-01-05 | 0.0 | 0.0 | 0.0 | 0.0 | . df[&quot;Date&quot;] = pd.to_datetime(df[&quot;Date&quot;], format=&#39;%m-%d-%Y&#39;) . TypeError Traceback (most recent call last) ~/.local/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in _convert_listlike_datetimes(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact) 431 try: --&gt; 432 values, tz = conversion.datetime_to_datetime64(arg) 433 return DatetimeIndex._simple_new(values, name=name, tz=tz) pandas/_libs/tslibs/conversion.pyx in pandas._libs.tslibs.conversion.datetime_to_datetime64() TypeError: Unrecognized value type: &lt;class &#39;str&#39;&gt; During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) &lt;ipython-input-15-e9a61e81ff3b&gt; in &lt;module&gt; -&gt; 1 df[&#34;Date&#34;] = pd.to_datetime(df[&#34;Date&#34;], format=&#39;%m-%d-%Y&#39;) ~/.local/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache) 726 result = arg.map(cache_array) 727 else: --&gt; 728 values = convert_listlike(arg._values, format) 729 result = arg._constructor(values, index=arg.index, name=arg.name) 730 elif isinstance(arg, (ABCDataFrame, abc.MutableMapping)): ~/.local/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in _convert_listlike_datetimes(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact) 433 return DatetimeIndex._simple_new(values, name=name, tz=tz) 434 except (ValueError, TypeError): --&gt; 435 raise e 436 437 if result is None: ~/.local/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in _convert_listlike_datetimes(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact) 398 try: 399 result, timezones = array_strptime( --&gt; 400 arg, format, exact=exact, errors=errors 401 ) 402 if &#34;%Z&#34; in format or &#34;%z&#34; in format: pandas/_libs/tslibs/strptime.pyx in pandas._libs.tslibs.strptime.array_strptime() ValueError: time data &#39;1995-01-01&#39; does not match format &#39;%m-%d-%Y&#39; (match) . df.head() . Unnamed: 0 Date temperature . 0 0 | 1995-01-01 | 72.4 | . 1 1 | 1995-01-02 | 73.5 | . 2 2 | 1995-01-03 | 72.6 | . 3 3 | 1995-01-04 | 75.2 | . 4 4 | 1995-01-05 | 74.8 | . df.plot(x=&#39;Date&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd44941efd0&gt; . df.loc[df[&#39;temperature&#39;] &lt; 0] . Date temperature . 664 1996-10-26 | -99.0 | . 1323 1998-08-16 | -99.0 | . 1453 1998-12-24 | -99.0 | . 1454 1998-12-25 | -99.0 | . 1459 1998-12-30 | -99.0 | . 1460 1998-12-31 | -99.0 | . 1470 1999-01-10 | -99.0 | . 2725 2002-06-18 | -99.0 | . 2726 2002-06-19 | -99.0 | . 2727 2002-06-20 | -99.0 | . 2728 2002-06-21 | -99.0 | . 2855 2002-10-26 | -99.0 | . 2934 2003-01-13 | -99.0 | . 4622 2007-08-28 | -99.0 | . 5015 2008-09-24 | -99.0 | . 5212 2009-04-09 | -99.0 | . 6976 2014-02-06 | -99.0 | . 7739 2016-03-10 | -99.0 | . 7985 2016-11-11 | -99.0 | . 8718 2018-11-14 | -99.0 | . 8721 2018-11-17 | -99.0 | . 8879 2019-04-24 | -99.0 | . 8901 2019-05-16 | -99.0 | . 8902 2019-05-17 | -99.0 | . 8903 2019-05-18 | -99.0 | . idx = df.loc[df[&quot;temperature&quot;] &lt; 0].index . for i in range(-4,5): print(df.iloc[idx[0] + i][&#39;temperature&#39;]) . 82.9 82.1 79.6 84.3 -99.0 83.7 81.0 82.0 81.4 . idx = df.loc[df[&#39;temperature&#39;] &lt; 0].index . for i in idx: if df.iloc[i+1][1] &gt; 0: df.iloc[i,1] = (df.iloc[i-1, 1] + df.iloc[i+1, 1]) / 2 else: df.iloc[i,1] = (df.iloc[i-1, 1]) . # for j in range(-4,5): # print(df.iloc[i + j][&#39;temperature&#39;]) . df.plot(x=&#39;Date&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd44b927668&gt; . df.describe() . temperature . count 9158.000000 | . mean 83.407043 | . std 4.730817 | . min 69.700000 | . 25% 79.400000 | . 50% 83.800000 | . 75% 87.000000 | . max 99.000000 | . df.loc[df[&#39;temperature&#39;] &gt;= 99] . Date temperature . 87 1995-03-29 | 99.0 | . 172 1995-06-22 | 99.0 | . idx = df.loc[df[&#39;temperature&#39;] &gt;= 99].index . for i in range(-4,5): print(df.iloc[87 + i][&#39;temperature&#39;]) . 84.0 84.2 82.6 84.2 99.0 85.1 84.3 84.7 84.6 . for i in range(-4,5): print(df.iloc[172 + i][&#39;temperature&#39;]) . 89.7 89.9 91.3 86.5 99.0 84.1 85.6 85.1 87.4 . for i in idx: if df.iloc[i+1][1] &lt; 99: df.iloc[i,1] = (df.iloc[i-1, 1] + df.iloc[i+1, 1]) / 2 else: df.iloc[i,1] = (df.iloc[i-1, 1]) . df.plot(x=&#39;Date&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd44b848ac8&gt; . df.describe() . temperature . count 9158.00000 | . mean 83.40398 | . std 4.72526 | . min 69.70000 | . 25% 79.40000 | . 50% 83.80000 | . 75% 87.00000 | . max 97.90000 | . idx = df.loc[df[&#39;temperature&#39;] == max(df[&quot;temperature&quot;])].index . for i in range(-4,5): print(df.loc[idx + i]) . Date temperature 1239 1998-05-24 93.8 Date temperature 1240 1998-05-25 93.1 Date temperature 1241 1998-05-26 94.0 Date temperature 1242 1998-05-27 97.8 Date temperature 1243 1998-05-28 97.9 Date temperature 1244 1998-05-29 96.1 Date temperature 1245 1998-05-30 92.6 Date temperature 1246 1998-05-31 92.5 Date temperature 1247 1998-06-01 91.4 . df.shape . (9158, 2) . dff = df.temperature . df.to_csv(&#39;processed-temperature.csv&#39;) . from pandas.plotting import lag_plot . lag_plot(df[&#39;temperature&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd4493686d8&gt; . df.values . array([[Timestamp(&#39;1995-01-01 00:00:00&#39;), 72.4], [Timestamp(&#39;1995-01-02 00:00:00&#39;), 73.5], [Timestamp(&#39;1995-01-03 00:00:00&#39;), 72.6], ..., [Timestamp(&#39;2020-01-25 00:00:00&#39;), 76.8], [Timestamp(&#39;2020-01-26 00:00:00&#39;), 78.7], [Timestamp(&#39;2020-01-27 00:00:00&#39;), 80.0]], dtype=object) . dataframe = pd.concat([df[&#39;temperature&#39;].shift(1), df.temperature], axis=1) dataframe.columns = [&#39;t-1&#39;, &#39;t+1&#39;] result = dataframe.corr() print(result) . t-1 t+1 t-1 1.000000 0.933585 t+1 0.933585 1.000000 . from pandas.plotting import autocorrelation_plot . autocorrelation_plot(df[&#39;temperature&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd44baeb4e0&gt; . autocorrelation_plot? . import keras . Using TensorFlow backend. . from keras import layers . from keras import Sequential . model = Sequential() model.add(layers.Embedding(input_dim=1000, output_dim=64)) model.add(layers.LSTM(128)) model.add(layers.Dense(10)) model.summary() . WARNING:tensorflow:From /home/vigneshwaran/environments/base/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating: Colocations handled automatically by placer. _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_1 (Embedding) (None, None, 64) 64000 _________________________________________________________________ lstm_1 (LSTM) (None, 128) 98816 _________________________________________________________________ dense_1 (Dense) (None, 10) 1290 ================================================================= Total params: 164,106 Trainable params: 164,106 Non-trainable params: 0 _________________________________________________________________ . model.fit? . rain = pd.read_csv(&#39;chennai_reservoir_rainfall.csv&#39;) . rain.plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fcd6c42d828&gt; . plt.plot(rain[&#39;POONDI&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fcd6c367240&gt;] . plt.plot(rain[&#39;CHEMBARAMBAKKAM&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fcd6c3313c8&gt;] . plt.plot(rain[&#39;REDHILLS&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fcd6c2f1c18&gt;] . plt.plot(rain[&#39;CHOLAVARAM&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fcd6c2413c8&gt;] . values = pd.DataFrame(df[&#39;temperature&#39;].values) dataframe = pd.concat([values.shift(1), values], axis=1) dataframe.columns = [&#39;t-1&#39;, &#39;t+1&#39;] X = dataframe.values train, test = X[1:len(X)-7], X[len(X)-7:] train_X, train_y = train[:,0], train[:,1] test_X, test_y = test[:,0], test[:,1] . values = pd.DataFrame(df[&#39;temperature&#39;].values) . import keras . from keras import layers . from keras import Sequential . from keras import backend as K cfg = K.tf.ConfigProto() cfg.gpu_options.allow_growth = True K.set_session(K.tf.Session(config=cfg)) . model = Sequential() model.add(layers.Embedding(input_dim=1000, output_dim=64)) model.add(layers.SimpleRNN(32)) model.add(layers.Dense(1)) model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_10 (Embedding) (None, None, 64) 64000 _________________________________________________________________ simple_rnn_7 (SimpleRNN) (None, 32) 3104 _________________________________________________________________ dense_6 (Dense) (None, 1) 33 ================================================================= Total params: 67,137 Trainable params: 67,137 Non-trainable params: 0 _________________________________________________________________ . . x = train_X . y = train_y . model.compile(loss=&#39;mae&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) . model.fit(x, y, epochs=20, batch_size=64) . Epoch 1/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.9561 - acc: 0.0162 Epoch 2/20 9150/9150 [==============================] - 0s 15us/step - loss: 1.7303 - acc: 0.0223 Epoch 3/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.5872 - acc: 0.0219 Epoch 4/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.4945 - acc: 0.0215 Epoch 5/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.4398 - acc: 0.0225 Epoch 6/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3975 - acc: 0.0223 Epoch 7/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3718 - acc: 0.0246 Epoch 8/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3511 - acc: 0.0243 Epoch 9/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3421 - acc: 0.0234 Epoch 10/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3356 - acc: 0.0249 Epoch 11/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3223 - acc: 0.0264 Epoch 12/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3219 - acc: 0.0232 Epoch 13/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3123 - acc: 0.0235 Epoch 14/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3165 - acc: 0.0242 Epoch 15/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3084 - acc: 0.0264 Epoch 16/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3106 - acc: 0.0267 Epoch 17/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3069 - acc: 0.0252 Epoch 18/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3023 - acc: 0.0249 Epoch 19/20 9150/9150 [==============================] - 0s 16us/step - loss: 1.3015 - acc: 0.0264 Epoch 20/20 9150/9150 [==============================] - 0s 17us/step - loss: 1.3031 - acc: 0.0243 . &lt;keras.callbacks.History at 0x7fd326e934a8&gt; . test_Res = model.predict(test_X) . mean_squared_error(test_Res, test_y) . 1.6229071366121768 . plt.plot(test_y) plt.plot(test_Res, color=&#39;red&#39;) plt.show() . model1 = Sequential() model1.add(layers.Embedding(input_dim=1000, output_dim=64)) model1.add(layers.LSTM(64)) model1.add(layers.Dense(1)) model1.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_9 (Embedding) (None, None, 64) 64000 _________________________________________________________________ lstm_3 (LSTM) (None, 64) 33024 _________________________________________________________________ dense_5 (Dense) (None, 1) 65 ================================================================= Total params: 97,089 Trainable params: 97,089 Non-trainable params: 0 _________________________________________________________________ . model1.compile(loss=&#39;mae&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) . model1.fit(x, y, epochs=20, batch_size=64) . Epoch 1/20 9150/9150 [==============================] - 0s 26us/step - loss: 1.2691 - acc: 0.0263 Epoch 2/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2707 - acc: 0.0247 Epoch 3/20 9150/9150 [==============================] - 0s 28us/step - loss: 1.2720 - acc: 0.0258 Epoch 4/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2726 - acc: 0.0255 Epoch 5/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2708 - acc: 0.0243 Epoch 6/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2703 - acc: 0.0247 Epoch 7/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2722 - acc: 0.0247 Epoch 8/20 9150/9150 [==============================] - 0s 31us/step - loss: 1.2731 - acc: 0.0252 Epoch 9/20 9150/9150 [==============================] - 0s 29us/step - loss: 1.2721 - acc: 0.0249 Epoch 10/20 9150/9150 [==============================] - 0s 28us/step - loss: 1.2715 - acc: 0.0257 Epoch 11/20 9150/9150 [==============================] - 0s 34us/step - loss: 1.2730 - acc: 0.0250 Epoch 12/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2706 - acc: 0.0259 Epoch 13/20 9150/9150 [==============================] - 0s 26us/step - loss: 1.2726 - acc: 0.0245 Epoch 14/20 9150/9150 [==============================] - 0s 36us/step - loss: 1.2736 - acc: 0.0263 Epoch 15/20 9150/9150 [==============================] - 0s 29us/step - loss: 1.2722 - acc: 0.0256 Epoch 16/20 9150/9150 [==============================] - 0s 26us/step - loss: 1.2758 - acc: 0.0247 Epoch 17/20 9150/9150 [==============================] - 0s 27us/step - loss: 1.2773 - acc: 0.0246 Epoch 18/20 9150/9150 [==============================] - 0s 32us/step - loss: 1.2715 - acc: 0.0250 Epoch 19/20 9150/9150 [==============================] - 0s 31us/step - loss: 1.2705 - acc: 0.0260 Epoch 20/20 9150/9150 [==============================] - 0s 31us/step - loss: 1.2716 - acc: 0.0254 . &lt;keras.callbacks.History at 0x7fd327581b38&gt; . test_LS = model1.predict(test_X) . mean_squared_error(test_LS, test_y) . 1.4905017587825284 . plt.plot(test_y) plt.plot(test_LS, color=&#39;red&#39;) plt.show() .",
            "url": "https://vignesh34v.github.io/vigneshwaran/2020/11/12/EDA.html",
            "relUrl": "/2020/11/12/EDA.html",
            "date": " • Nov 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://vignesh34v.github.io/vigneshwaran/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://vignesh34v.github.io/vigneshwaran/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://vignesh34v.github.io/vigneshwaran/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://vignesh34v.github.io/vigneshwaran/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}